<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <!--External Libraries!-->
  <!--<script type="text/javascript" src="js/gl-matrix.js"></script>!-->
  <script type="text/javascript" src="/libs/GLEAT/js/gl-matrix-min.js"></script>
  <script type="text/javascript" src="/libs/GLEAT/js/webgl-utils.js"></script>
  <script type="text/javascript" src="/libs/GLEAT/js/webgl-debug.js"></script>
  <script type="text/javascript" src="/libs/GLEAT/js/numeric-1.2.6.min.js"></script>
  <script type="text/javascript" src="/libs/GLEAT/js/jquery-1.11.1.min.js"></script>
  <!--D3 stuff!-->
  <script src="node_modules/d3/d3.min.js"></script>
  <!--Plot.ly!-->
  <script src="libs/plotly.min.js"></script>
  <!--DSP library!-->
  <script src="libs/dsp.js"></script>

  <script src="libs/projection.js"></script>

  <!--Our Scripts!-->
  <script src="/libs/GLEAT/Geometry/PolyMesh.js"></script>
  <script src="/libs/GLEAT/Geometry/Primitives3D.js"></script>
  <script src="/libs/GLEAT/Geometry/Cameras3D.js"></script>
  <script src="/libs/GLEAT/DrawingUtils/Shaders.js"></script>
  <script src="/libs/GLEAT/DrawingUtils/SimpleDraw.js"></script>
  <script src="/libs/GLEAT/Viewers/SimpleMeshCanvas.js"></script>
  <script src="main/SceneFile.js"></script>
  <script src="main/image-sources.js"></script>
  <script src="main/SoundTools.js"></script>
</head>

<link href='https://fonts.googleapis.com/css?family=Poiret+One' rel='stylesheet' type='text/css'>
<link type="text/css" rel="stylesheet" href="./main/style.css"/>

<style>

@import url(/main/style.css);

/* wideer body than specified in style.css*/
body {
  max-width: 960px;
}

#graph{
  min-height: 450px;
}

#impulsePlot {
  margin-left: auto;
}

.title {
  font-weight: bold;
  text-shadow:
    -.1px -.1px 0 #fff,
    .1px -1px 0 #fff,
    -1px .1px 0 #fff,
    .1px .1px 0 #fff; 
  pointer-events: none;
  font-size: 48px;
}

.row {
  display: inline-block;
  margin-left: 40px;
  margin-right: 40px;
  margin-bottom: 20px;
  text-align: center;
}

.center {
  margin-top: 20px;
  margin-bottom: 20px;
}

button {
  outline: none;
  background-color: #a3a3a3;
  border: 2px solid #000;
  color: white;
  padding: 15px 32px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 16px;
  margin: 4px 6px;
  cursor: pointer;
  border-radius: 10px;
}

#sourceorder {
  font-size: 22px;
}

button:hover {
  opacity: 0.6;
}

button.source {
  background-color: blue;
}

button.receiver {
  background-color: red;
}

button.external {
  background-color: #323232
}

button.reflect {
  border: 2px solid #000;
}

button.extract {
  border: 2px solid #FF0000;
}

button.response {
  border: 2px solid #000;
}

button.play {
  color: #000;
}

button.pause {
  color: red;
}

button.convolve {
  border: 1px solid #000;
  background-color: #E7550D;
  padding: 6px 16px;
}

g.subplot.xy > rect {
  fill: none; !important
}

.blue {
  color: blue;
}

.red {
  color: red;
}

.progress {
  font-size: 24px;
  padding-left: 20px;
  padding-right: 10px;
}

</style>

<body>

<header>
  <h1>Specular Reflections</h1>
  <span class="credits">by 
    <a href="https://github.com/ctralie">Chris Tralie</a> and 
    <a href="https://github.com/bmershon/">Brooks Mershon</a>
  </span>
</header>

<p class="note">
   Specular reflections between a <span class="blue"><b>sound source</b></span> and a <span class="red"><b>sound receiver</b></span> can be used to simulate an impulse response in a 3D environment. Each polygon has material properties that describe how much sound is absorbed or reflected, and the polygons are placed somewhere within a scene graph.
</p>

<div class="center">
  You can load a new <code>.scn</code> file
  <span class="progress">&rarr;</span>
  <input type = "file" class="inputfile" id = "sceneInput">
</div>

<aside style="text-indent:-.7em;">
  *Use <strong>WASD</strong> to walk.<br>
  <strong>Mouse</strong> to look.<br>
  <strong>E</strong> and <strong>C</strong> move up and down.
</aside>

<div class="center">
  <h2>Click to change position</h2>
  <button class="source" type="button" id = "sourceButton" onclick="callViewFromSource()">Source</button>
  <button class="receiver" type="button" id = "receiverButton" onclick="callViewFromReceiver()">Receiver</button>
  <button class="external" type="button" id = "externalButton" onclick="callViewFromExternal()">External</button>
</div>

<canvas id="GLCanvas1" width="960" height="500"></canvas>

<div class="center">
  <span>
    <input type="checkbox" id="meshEdgesCheckbox" checked> Mesh Edges
  </span>
  </span>
    <input type="checkbox" id="displayImageSourcesCheckbox" checked=""> Image Sources
  </span>
  <span>
    <input type="checkbox" id="displayPathsCheckbox" checked> Paths
  </span>
</div>

<div class="center">
  <button class="reflect" type="button" id = "sourcesButton" onclick="callComputeImageSources()">Compute Image Sources of Order</button> <input type="text" value=1 id="sourceorder" size="1"></input>
  <span class="progress">&rarr;<span>
  <button class="extract" type="button" id = "pathsButton" onclick="callExtractPaths()">Extract Paths</button>
  <span class="progress">&rarr;</span>
  <button class="response" type="button" id = "sourceButton" onclick="callComputeImpulseResponse()">Compute Impulse Response</button>
</div>

<hr>

<div class="center">
  <div>
    <span class="progress">&darr;</span>
  </div>
  <h2>Choose some tunes</h2>
  <input type = "file" id = "audioInput">
  <div>
    <span class="progress">&darr;</span>
  </div>
</div>

<hr>

<div class="center">
  <div class="wrapper">
    <p>
      Perform the Fast Fourier Transform.
    </p>
  </div>
  <button class="convolve" type = "button" onclick = "recomputeConv()">Convolve</button>
</div>

<hr>

<div class="center">
  <div class="row">
    <h3>♬ Source Signal ♬</h3>
    <button type = "button" class="play" onclick = "playAudioSource()">&#9654;</button>
    <button type = "button" class="pause" onclick = "pauseAudio()">&#10073;&#10073;</button>
  </div>

  <div class="row">
    <h3>Impulse Response</h3>
    <button type = "button" class="play" onclick = "playAudioImpulse()">&#9654;</button>
    <button type = "button" class="pause" onclick = "pauseAudio()">&#10073;&#10073;</button>
  </div>

  <div class="row">
    <h3>Convolution</h3>
    <button type = "button" class="play" onclick = "playAudioConv()">&#9654;</button>
    <button type = "button" class="pause" onclick = "pauseAudio()">&#10073;&#10073;</button>
  </div>
</div>

<hr>

<div class="wrapper">
  <p>
    The first non-zero amplitude represents the first <em>echo</em> in the scene. The highest amplitude likely corresponds to the shortest reflection path, but sound-deadening properties of the materals in the scene may cause a short path to result in a very faint <em>echo</em>.
  </p>
</div>  

<div class="center">
    <h2>Graph of the impulse response</h2>
</div>

<div id="graph">
  <div width="1080" id="impulsePlot"></div>
</div>

<script>
var glcanvas = document.getElementById("GLCanvas1");

glcanvas.addEventListener("contextmenu", function(e){
  e.stopPropagation();
  e.preventDefault();
  return false;
}); //Need this to disable the menu that pops up on right clicking

loadSceneFromFile('/scenes/CeilingFloorBox.scn', glcanvas);

var sceneInput = document.getElementById('sceneInput');
sceneInput.addEventListener('change', function(e) {
  var reader = new FileReader();
  reader.onload = function(e) {
    var data = e.target.result;
    try {
      data = JSON.parse(data);
    }
    catch(error) {
      alert("Error parsing scene file.  Check your JSON syntax");
      throw(error);
    }
    setupScene(data, glcanvas);
  }
  reader.readAsText(sceneInput.files[0]);
});

var meshEdgesCheckbox = document.getElementById('meshEdgesCheckbox');
meshEdgesCheckbox.addEventListener('change', function(e) {
  glcanvas.drawEdges = meshEdgesCheckbox.checked;
  requestAnimFrame(glcanvas.repaint);
});
meshEdgesCheckbox.checked = true;

var displayImageSourcesCheckbox = document.getElementById('displayImageSourcesCheckbox');
displayImageSourcesCheckbox.addEventListener('change', function(e) {
  glcanvas.drawImageSources = displayImageSourcesCheckbox.checked;
  requestAnimFrame(glcanvas.repaint);
});
displayImageSourcesCheckbox.checked = true;
var displayPathsCheckbox = document.getElementById('displayPathsCheckbox');
displayPathsCheckbox.addEventListener('change', function(e) {
  glcanvas.drawPaths = displayPathsCheckbox.checked;
  requestAnimFrame(glcanvas.repaint);
});
displayPathsCheckbox.checked = true;

function callViewFromSource() {
  glcanvas.viewFromSource();
}
function callViewFromReceiver() {
  glcanvas.viewFromReceiver();
}
function callViewFromExternal() {
  glcanvas.viewFromExternal();
}
function callComputeImageSources() {
  var orderTxt = document.getElementById("sourceorder");
  var order = parseInt(orderTxt.value);
  glcanvas.computeImageSources(order);
}
function callExtractPaths() {
  glcanvas.extractPaths();
}
function callComputeImpulseResponse() {
  glcanvas.computeImpulseResponse();
}
///////////////////////////////////////////
//             Audio stuff               //
///////////////////////////////////////////
var source = null,
    analyser = null,
    playing = true,
    buffer = null,
    impbuffer = null,
    convbuffer = null,
    context = new (window.AudioContext || window.webkitAudioContext)();

function playAudioSource() {
  playAudio(buffer);
}

function playAudioImpulse() {
  playAudio(impbuffer);
}

function playAudioConv() {
  playAudio(convbuffer);
}

function playAudio(b) {
  if (context === null) {
    return;
  }
  if (!(source === null) && playing) {
    source.stop();
  }
  source = context.createBufferSource();
  source.buffer = b;
  analyser = context.createAnalyser();
  source.connect(analyser);
  analyser.connect(context.destination);
  source.start();
  playing = true;
}

function pauseAudio() {
  if (source === null) {
    return;
  }
  playing = false;
  source.stop();
}

var audioInput = document.getElementById('audioInput');
audioInput.addEventListener('change', function(e) {
  var reader = new FileReader();
  reader.onload = function(e) {
    var data = e.target.result;
    if(context.decodeAudioData) {
      context.decodeAudioData(data, function(buff) {
      buffer = buff;
      globalFs = buffer.sampleRate;
      console.log("Loaded audio with sample rate " + globalFs);
      }, function(e) {
        console.log(e);
      });
    }
  }        
  reader.readAsArrayBuffer(audioInput.files[0]);
});

function recomputeConv() {
  doConvolution(buffer, impbuffer);
}
</script>

</body>
</html>