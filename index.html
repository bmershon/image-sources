<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<!--External Libraries!-->
<!--<script type="text/javascript" src="js/gl-matrix.js"></script>!-->
<script type="text/javascript" src = "/libs/GLEAT/js/gl-matrix-min.js"></script>
<script type="text/javascript" src="/libs/GLEAT/js/webgl-utils.js"></script>
<script type="text/javascript" src="/libs/GLEAT/js/webgl-debug.js"></script>
<script type="text/javascript" src="/libs/GLEAT/js/numeric-1.2.6.min.js"></script>
<script type="text/javascript" src="/libs/GLEAT/js/jquery-1.11.1.min.js"></script>
<!--D3 stuff!-->
<script src="node_modules/d3/d3.min.js"></script>
<!--Plot.ly!-->
<script src="libs/plotly.min.js"></script>
<!--DSP library!-->
<script src="libs/dsp.js"></script>

<script src="libs/projection.js"></script>

<!--Our Scripts!-->
<script src="/libs/GLEAT/Geometry/PolyMesh.js"></script>
<script src="/libs/GLEAT/Geometry/Primitives3D.js"></script>
<script src="/libs/GLEAT/Geometry/Cameras3D.js"></script>
<script src="/libs/GLEAT/DrawingUtils/Shaders.js"></script>
<script src="/libs/GLEAT/DrawingUtils/SimpleDraw.js"></script>
<script src="/libs/GLEAT/Viewers/SimpleMeshCanvas.js"></script>
<script src="main/SceneFile.js"></script>
<script src="main/image-sources.js"></script>
<script src="main/SoundTools.js"></script>
</head>
<link href='https://fonts.googleapis.com/css?family=Poiret+One' rel='stylesheet' type='text/css'>
<link type="text/css" rel="stylesheet" href="./main/style.css"/>

<body>

<header>
  <h1>Specular Reflections</h1>
  <span class="credits">by 
    <a href="https://github.com/ctralie">Chris Tralie</a> and 
    <a href="https://github.com/bmershon/">Brooks Mershon</a>
  </span>
</header>

<div class="scene_picker">
  <input type = "file" id = "sceneInput">
</div>

<p class="note">
   Specular reflections between a <span class="blue"><b>sound source</b></span> and a <span class="red"><b>sound receiver</b></span> can be used to simulate an impulse response in a 3D environment. Each polygon has material properties that describe how much sound is absorbed or reflected, and the polygons are placed somewhere within a scene graph.
</p>

<div class="center">
  <h2>Click to change position</h2>
  <div>
    <button class="source" type="button" id = "sourceButton" onclick="callViewFromSource()">Source</button>
    <button class="receiver" type="button" id = "receiverButton" onclick="callViewFromReceiver()">Receiver</button>
    <button class="external" type="button" id = "externalButton" onclick="callViewFromExternal()">External</button>
  </div>
</div>

<canvas id="GLCanvas1" width="960" height="500"></canvas>

<div class="center">
  <span>
    <input type="checkbox" id="meshEdgesCheckbox" checked> Display Mesh Edges
  </span>
  </span>
    <input type="checkbox" id="displayImageSourcesCheckbox" checked=""> Display Image Sources
  </span>
  <span>
    <input type="checkbox" id="displayPathsCheckbox" checked> Display Paths
  </span>
</div>

<div class="center">
  <button class="reflect" type="button" id = "sourcesButton" onclick="callComputeImageSources()">Compute Image Sources of Order</button> <input type="text" value=1 id="sourceorder" size="1"></input>
  <span class="progress">&rarr;<span>
  <button class="extract" type="button" id = "pathsButton" onclick="callExtractPaths()">Extract Paths</button>
  <span class="progress">&rarr;</span>
  <button class="response" type="button" id = "sourceButton" onclick="callComputeImpulseResponse()">Compute Impulse Response</button>
</div>

<hr>

<div class="center">
  <div>
    <span class="progress">&darr;</span>
  </div>
  <h2>Choose some tunes</h2>
  <input type = "file" id = "audioInput">
  <div>
    <button class="convolve" type = "button" onclick = "recomputeConv()">Convolve</button>
  </div>
  <div>
    <span class="progress">&darr;</span>
  </div>
</div>

<hr>

<div class="center">
  <div class="row">
    <h3>♬ Source Signal ♬</h3>
    <button type = "button" class="play" onclick = "playAudioSource()">&#9654;</button>
    <button type = "button" class="pause" onclick = "pauseAudio()">&#10073;&#10073;</button>
  </div>

  <div class="row">
    <h3>Impulse Response</h3>
    <button type = "button" class="play" onclick = "playAudioImpulse()">&#9654;</button>
    <button type = "button" class="pause" onclick = "pauseAudio()">&#10073;&#10073;</button>
  </div>

  <div class="row">
    <h3>Convolution</h3>
    <button type = "button" class="play" onclick = "playAudioConv()">&#9654;</button>
    <button type = "button" class="pause" onclick = "pauseAudio()">&#10073;&#10073;</button>
  </div>
</div>

<hr>

<p class="note">
  The first non-zero amplitude represents the first <em>echo</em> in the scene. The highest amplitude likely corresponds to the shortest reflection path, but sound-deadening properties of the materals in the scene may cause a short path to result in a very faint <em>echo</em>.
</p>  

<div class="center">
    <h2>Graph of the impulse response</h2>
</div>

<div id="graph">
  <div width="1080" id="impulsePlot"></div>
</div>

<script>
var glcanvas = document.getElementById("GLCanvas1");

glcanvas.addEventListener("contextmenu", function(e){
  e.stopPropagation();
  e.preventDefault();
  return false;
}); //Need this to disable the menu that pops up on right clicking

loadSceneFromFile('/scenes/CeilingFloorBox.scn', glcanvas);

var sceneInput = document.getElementById('sceneInput');
sceneInput.addEventListener('change', function(e) {
  var reader = new FileReader();
  reader.onload = function(e) {
    var data = e.target.result;
    try {
      data = JSON.parse(data);
    }
    catch(error) {
      alert("Error parsing scene file.  Check your JSON syntax");
      throw(error);
    }
    setupScene(data, glcanvas);
  }
  reader.readAsText(sceneInput.files[0]);
});

var meshEdgesCheckbox = document.getElementById('meshEdgesCheckbox');
meshEdgesCheckbox.addEventListener('change', function(e) {
  glcanvas.drawEdges = meshEdgesCheckbox.checked;
  requestAnimFrame(glcanvas.repaint);
});
meshEdgesCheckbox.checked = true;

var displayImageSourcesCheckbox = document.getElementById('displayImageSourcesCheckbox');
displayImageSourcesCheckbox.addEventListener('change', function(e) {
  glcanvas.drawImageSources = displayImageSourcesCheckbox.checked;
  requestAnimFrame(glcanvas.repaint);
});
displayImageSourcesCheckbox.checked = true;
var displayPathsCheckbox = document.getElementById('displayPathsCheckbox');
displayPathsCheckbox.addEventListener('change', function(e) {
  glcanvas.drawPaths = displayPathsCheckbox.checked;
  requestAnimFrame(glcanvas.repaint);
});
displayPathsCheckbox.checked = true;

function callViewFromSource() {
  glcanvas.viewFromSource();
}
function callViewFromReceiver() {
  glcanvas.viewFromReceiver();
}
function callViewFromExternal() {
  glcanvas.viewFromExternal();
}
function callComputeImageSources() {
  var orderTxt = document.getElementById("sourceorder");
  var order = parseInt(orderTxt.value);
  glcanvas.computeImageSources(order);
}
function callExtractPaths() {
  glcanvas.extractPaths();
}
function callComputeImpulseResponse() {
  glcanvas.computeImpulseResponse();
}
///////////////////////////////////////////
//             Audio stuff               //
///////////////////////////////////////////
var source = null,
    analyser = null,
    playing = true,
    buffer = null,
    impbuffer = null,
    convbuffer = null,
    context = new (window.AudioContext || window.webkitAudioContext)();

function playAudioSource() {
  playAudio(buffer);
}

function playAudioImpulse() {
  playAudio(impbuffer);
}

function playAudioConv() {
  playAudio(convbuffer);
}

function playAudio(b) {
  if (context === null) {
    return;
  }
  if (!(source === null) && playing) {
    source.stop();
  }
  source = context.createBufferSource();
  source.buffer = b;
  analyser = context.createAnalyser();
  source.connect(analyser);
  analyser.connect(context.destination);
  source.start();
  playing = true;
}

function pauseAudio() {
  if (source === null) {
    return;
  }
  playing = false;
  source.stop();
}

var audioInput = document.getElementById('audioInput');
audioInput.addEventListener('change', function(e) {
  var reader = new FileReader();
  reader.onload = function(e) {
    var data = e.target.result;
    if(context.decodeAudioData) {
      context.decodeAudioData(data, function(buff) {
      buffer = buff;
      globalFs = buffer.sampleRate;
      console.log("Loaded audio with sample rate " + globalFs);
      }, function(e) {
        console.log(e);
      });
    }
  }        
  reader.readAsArrayBuffer(audioInput.files[0]);
});

function recomputeConv() {
  doConvolution(buffer, impbuffer);
}
</script>

</body>
</html>